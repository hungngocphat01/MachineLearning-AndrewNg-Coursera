{
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Import libraries"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "import numpy as np \n",
                "import scipy.io as sio \n",
                "import scipy.optimize as opt\n",
                "import matplotlib.pyplot as plt \n",
                "import time\n",
                "from IPython.display import clear_output"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Load data "
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "training_data = sio.loadmat(\"ex4data1.mat\")\n",
                "X: np.array = np.array(training_data['X'], dtype=np.float128)\n",
                "y: np.array = np.array(training_data['y'], dtype=np.float128)\n",
                "# Map label 10 from matlab back to 0 (python has index 0)\n",
                "y[y == 10] = 0\n",
                "\n",
                "test_theta_data = sio.loadmat(\"ex4weights.mat\")\n",
                "TestTheta1: np.array = np.array(test_theta_data['Theta1'], dtype=np.double)\n",
                "TestTheta2: np.array = np.array(test_theta_data['Theta2'], dtype=np.double)\n",
                "print(\"Data loaded\")\n",
                "print(\"Size of X:\", X.shape)\n",
                "print(\"Size of y:\", y.shape)\n",
                "print(\"Size of TestTheta1:\", TestTheta1.shape)\n",
                "print(\"Size of TestTheta2:\", TestTheta2.shape)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Data loaded\n",
                        "Size of X: (5000, 400)\n",
                        "Size of y: (5000, 1)\n",
                        "Size of TestTheta1: (25, 401)\n",
                        "Size of TestTheta2: (10, 26)\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Display 100 random images"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# Create 100 random indices\n",
                "# randIdx = np.random.randint(0, X.shape[0], 100).reshape(10, 10)\n",
                "# fig, ax = plt.subplots(10, 10)\n",
                "\n",
                "# for i in range(randIdx.shape[0]):\n",
                "#     for j in range(randIdx.shape[1]):\n",
                "#         example = X[randIdx[i, j]]\n",
                "#         example = example.reshape((20, 20)).T\n",
                "#         ax[i, j].imshow(example, vmin=-1, vmax=1, cmap='gray')\n",
                "#         ax[i, j].set_xticks([])\n",
                "#         ax[i, j].set_yticks([])\n",
                "# plt.show()"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Define utility functions"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "def sigmoid(z):\n",
                "    return 1/(1 + np.exp(-z))\n",
                "def gsigmoid(z):\n",
                "    s = sigmoid(z)\n",
                "    return np.multiply(s, 1 - s)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Define hypothesis function (feed-forward algorithm)\n",
                "\n",
                "- Init `a1=x`\n",
                "- Add bias term to `a1`\n",
                "- Calculate `z2 = Theta1 * a1`\n",
                "- Calculate `a2 = sigmoid(z2)`\n",
                "- Calculate `z3 = Theta2 * a2`\n",
                "- Calculate `h = a3 = sigmoid(z3)`"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "source": [
                "def hypothesis(x, Theta1, Theta2):\n",
                "    a1 = np.vstack((1, x.reshape(-1, 1)))\n",
                "    z2 = Theta1 @ a1\n",
                "    a2 = np.vstack((1, sigmoid(z2).reshape(-1, 1)))\n",
                "    z3 = Theta2 @ a2 \n",
                "    h = sigmoid(z3)\n",
                "    return (\n",
                "        a1.reshape(-1, 1), \n",
                "        a2.reshape(-1, 1), \n",
                "        h.reshape(-1, 1), \n",
                "        z2.reshape(-1, 1), \n",
                "        z3.reshape(-1, 1)\n",
                "    )"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Define cost function and its gradient"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "source": [
                "def costFunction(X, y, lambd, nn_params, hidden_layer_size, output_layer_size):\n",
                "    m = X.shape[0]\n",
                "    input_layer_size = X.shape[1]\n",
                "    # nn_params: unrolled Theta1, Theta2 \n",
                "    # Extract Theta1, Theta2 from nn_params \n",
                "    Theta_vec = nn_params.reshape(-1, 1)\n",
                "    breakpnt = (input_layer_size + 1) * hidden_layer_size\n",
                "    Theta1 = Theta_vec[None:breakpnt, :].reshape((hidden_layer_size, input_layer_size + 1))\n",
                "    Theta2 = Theta_vec[breakpnt:None, :].reshape((output_layer_size, hidden_layer_size + 1))\n",
                "    \n",
                "    J = 0 \n",
                "    Theta1_grad = np.zeros(shape=Theta1.shape)\n",
                "    Theta2_grad = np.zeros(shape=Theta2.shape)\n",
                "    Delta1 = 0 \n",
                "    Delta2 = 0\n",
                "    for i in range(X.shape[0]):\n",
                "        x = X[i, :].reshape((-1, 1))\n",
                "        # Feed-forward\n",
                "        a1, a2, h, z2, z3 = hypothesis(x, Theta1, Theta2)\n",
                "        # print(np.sum(a1), np.sum(z2), np.sum(a2), np.sum(z3), np.sum(h))\n",
                "        # break\n",
                "        # Compute J \n",
                "        y_hop = np.zeros(output_layer_size).reshape(-1, 1)\n",
                "        y_hop[int(y[i])] = 1\n",
                "        j = -y_hop.T @ np.log(h) - (1 - y_hop).T @ np.log(1 - h)\n",
                "        J += float(j)\n",
                "\n",
                "        # Back propagation \n",
                "        delta3 = h - y_hop \n",
                "        delta2 = np.multiply(Theta2.T @ delta3, gsigmoid(np.vstack((0, z2))))\n",
                "        delta2 = delta2[1:None]\n",
                "        Delta1 += delta2 @ a1.T \n",
                "        Delta2 += delta3 @ a2.T \n",
                "    # Average \n",
                "    J *= 1/m \n",
                "    # Add regularized term for cost function \n",
                "    theta1_reg = Theta1\n",
                "    theta1_reg[:,0] = 0 \n",
                "    theta2_reg = Theta2\n",
                "    theta2_reg[:,0] = 0 \n",
                "    J += lambd/(2*m) * (np.sum(np.power(theta1_reg, 2)) + np.sum(np.power(theta2_reg, 2)))\n",
                "    # Regularized term for theta_gradient \n",
                "    Theta1_grad = (1/m * Delta1) + (lambd/m) * theta1_reg\n",
                "    Theta2_grad = (1/m * Delta2) + (lambd/m) * theta2_reg\n",
                "\n",
                "    # Unroll gradient \n",
                "    grad = np.vstack((Theta1_grad.reshape(-1, 1), Theta2_grad.reshape(-1, 1))).reshape(-1, 1)\n",
                "\n",
                "    return (float(J), grad)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Define functions to calculate and check numerical gradients"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "source": [
                "def numericalGradient(J, theta):\n",
                "    numgrad = np.zeros(shape=theta.shape)\n",
                "    for i in range(len(theta)):\n",
                "        e = np.power(10.0, -4, dtype=np.double)\n",
                "        epsilon_vec = np.zeros(shape=theta.shape)\n",
                "        epsilon_vec[i] = e \n",
                "\n",
                "        left_j, _ = J(theta - epsilon_vec)\n",
                "        right_j, _ = J(theta + epsilon_vec)\n",
                "        numgrad[i] = (right_j - left_j)/(2*e)\n",
                "    return numgrad\n",
                "\n",
                "def debugInitializeWeights(out_conn, in_conn):\n",
                "    W = np.zeros((out_conn, 1 + in_conn))\n",
                "    W = (np.sin(np.array(range(1, W.size+1)))/10).reshape(W.shape)\n",
                "    return W\n",
                "\n",
                "def initializeRandomWeights(L_in, L_out):\n",
                "    W = np.zeros((L_out, 1 + L_in))\n",
                "    e = 0.12 \n",
                "    W = np.random.rand(L_out, 1 + L_in) * 2 * e - e\n",
                "    return W\n",
                "\n",
                "\n",
                "def checkNumGradient(lamd):\n",
                "    input_layer_size = 3\n",
                "    hidden_layer_size = 5 \n",
                "    num_labels = 3 \n",
                "    m = 5\n",
                "\n",
                "    Theta1 = debugInitializeWeights(hidden_layer_size, input_layer_size)\n",
                "    Theta2 = debugInitializeWeights(num_labels, hidden_layer_size)\n",
                "    X = debugInitializeWeights(m, input_layer_size - 1)\n",
                "    y = (np.array(range(1, m+1)) % num_labels).reshape(-1, 1) \n",
                "\n",
                "    cost_func_ptr = lambda theta: costFunction(X, y, lamd, theta, hidden_layer_size, num_labels)\n",
                "    nn_params = np.concatenate((Theta1.reshape(-1, 1), Theta2.reshape(-1, 1)), axis=0)\n",
                "    # Compute numerical gradient\n",
                "    _, grad = cost_func_ptr(nn_params)\n",
                "    \n",
                "    num_grad = numericalGradient(cost_func_ptr, nn_params)\n",
                "\n",
                "    print(\"Visual check\")\n",
                "    print(np.hstack((num_grad.reshape(-1, 1), grad.reshape(-1, 1))))\n",
                "\n",
                "    diff = np.linalg.norm(num_grad - grad)/np.linalg.norm(num_grad + grad)\n",
                "    print(\"Errors:\", diff)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Check backpropagation implementation"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "source": [
                "checkNumGradient(0)\n",
                "checkNumGradient(10)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Visual check\n",
                        "[[ 1.11803447e-02  1.23162247e-02]\n",
                        " [ 1.59985736e-04  1.73828184e-04]\n",
                        " [ 2.40574911e-04  2.61455144e-04]\n",
                        " [ 9.99806171e-05  1.08701450e-04]\n",
                        " [ 3.51234892e-03  3.92471369e-03]\n",
                        " [ 1.85238738e-04  1.90101252e-04]\n",
                        " [ 2.14805114e-04  2.22272331e-04]\n",
                        " [ 4.68806571e-05  5.00872547e-05]\n",
                        " [-7.38445206e-03 -8.08459407e-03]\n",
                        " [ 4.01813982e-05  3.13170587e-05]\n",
                        " [-8.45539194e-06 -2.17840341e-05]\n",
                        " [-4.93183361e-05 -5.48569864e-05]\n",
                        " [-1.14921627e-02 -1.26669105e-02]\n",
                        " [-1.41811922e-04 -1.56130210e-04]\n",
                        " [-2.23937224e-04 -2.45506163e-04]\n",
                        " [-1.00175674e-04 -1.09164881e-04]\n",
                        " [-5.03401153e-03 -5.59342547e-03]\n",
                        " [-1.93432419e-04 -2.00036572e-04]\n",
                        " [-2.33539066e-04 -2.43630220e-04]\n",
                        " [-5.89309801e-05 -6.32313673e-05]\n",
                        " [ 2.88199720e-01  3.09347722e-01]\n",
                        " [ 1.43984919e-01  1.61067138e-01]\n",
                        " [ 1.43863505e-01  1.47036522e-01]\n",
                        " [ 1.44523776e-01  1.58268577e-01]\n",
                        " [ 1.43782027e-01  1.57616707e-01]\n",
                        " [ 1.44091438e-01  1.47236360e-01]\n",
                        " [ 9.15171609e-02  1.08133003e-01]\n",
                        " [ 4.55783837e-02  5.61633717e-02]\n",
                        " [ 4.62276140e-02  5.19510542e-02]\n",
                        " [ 4.53256195e-02  5.47353405e-02]\n",
                        " [ 4.58555620e-02  5.53082757e-02]\n",
                        " [ 4.60647729e-02  5.17752619e-02]\n",
                        " [ 9.55110886e-02  1.06270372e-01]\n",
                        " [ 4.81457641e-02  5.57611045e-02]\n",
                        " [ 4.77183372e-02  5.05568118e-02]\n",
                        " [ 4.74139729e-02  5.38805141e-02]\n",
                        " [ 4.82392839e-02  5.47407215e-02]\n",
                        " [ 4.74647220e-02  5.02929547e-02]]\n",
                        "Errors: 0.04560216019411723\n",
                        "Visual check\n",
                        "[[ 0.01118034  0.01231622]\n",
                        " [ 0.05471783  0.05473167]\n",
                        " [ 0.00870778  0.00872866]\n",
                        " [-0.04530817 -0.04529945]\n",
                        " [ 0.00351235  0.00392471]\n",
                        " [-0.01657969 -0.01657483]\n",
                        " [ 0.039634    0.03964147]\n",
                        " [ 0.05940838  0.05941158]\n",
                        " [-0.00738445 -0.00808459]\n",
                        " [-0.03260109 -0.03260995]\n",
                        " [-0.06000787 -0.0600212 ]\n",
                        " [-0.03224369 -0.03224923]\n",
                        " [-0.01149216 -0.01266691]\n",
                        " [ 0.05929463  0.05928031]\n",
                        " [ 0.03879333  0.03877176]\n",
                        " [-0.01737437 -0.01738336]\n",
                        " [-0.00503401 -0.00559343]\n",
                        " [-0.04525267 -0.04525927]\n",
                        " [ 0.00875909  0.008749  ]\n",
                        " [ 0.05471778  0.05471348]\n",
                        " [ 0.28819972  0.30934772]\n",
                        " [ 0.19854276  0.21562498]\n",
                        " [ 0.15233071  0.15550372]\n",
                        " [ 0.09911563  0.11286043]\n",
                        " [ 0.08624657  0.10008125]\n",
                        " [ 0.12732651  0.13047143]\n",
                        " [ 0.09151716  0.108133  ]\n",
                        " [ 0.10493988  0.11552487]\n",
                        " [ 0.07095472  0.07667816]\n",
                        " [ 0.01268435  0.02209407]\n",
                        " [-0.01414385 -0.00469114]\n",
                        " [ 0.0138704   0.01958089]\n",
                        " [ 0.09551109  0.10627037]\n",
                        " [ 0.10758221  0.11519755]\n",
                        " [ 0.08673561  0.08957408]\n",
                        " [ 0.03013977  0.03660632]\n",
                        " [-0.00944457 -0.00294313]\n",
                        " [ 0.00240549  0.00523372]]\n",
                        "Errors: 0.04282890954888133\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Define gradient descent function"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "source": [
                "def NesterovGradientDescent(cost_func, gamma, learning_rate, init_theta, max_iters):\n",
                "    # Prepare data for gradient descent\n",
                "    theta = init_theta.reshape(-1, 1)\n",
                "    v = np.zeros_like(theta)\n",
                "    change_rate = 0\n",
                "    cost_history = [0]\n",
                "\n",
                "    for i in range(max_iters):\n",
                "        J, grad = cost_func(theta - gamma * v)\n",
                "        v = v * gamma + learning_rate * grad \n",
                "        theta = theta - v \n",
                "        change_rate = cost_history[-1] - J\n",
                "        cost_history.append(J)\n",
                "\n",
                "        print(\"\\r\", \n",
                "            \"Iteration:\", i, \n",
                "            \"; Cost value:\", np.round(J, decimals=6), \n",
                "            \"; Changing rate:\", np.mean(change_rate).flatten(), \n",
                "            \"; Gradient:\", np.mean(grad).flatten(), end=\"\"\n",
                "        )\n",
                "    \n",
                "    return (cost_history, theta)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Train neural network"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "source": [
                "lambd = 10\n",
                "input_layer_size = X.shape[1]\n",
                "hidden_layer_size = 25\n",
                "output_layer_size = 10\n",
                "\n",
                "print(\"Initializing neural network\")\n",
                "init_Theta1 = initializeRandomWeights(input_layer_size, hidden_layer_size).reshape(-1, 1)\n",
                "init_Theta2 = initializeRandomWeights(hidden_layer_size, output_layer_size).reshape(-1, 1)\n",
                "init_Theta = np.vstack((init_Theta1, init_Theta2)).reshape(-1, 1)\n",
                "\n",
                "cost_func_ptr = lambda theta: costFunction(X, y, lambd, theta, hidden_layer_size, output_layer_size)\n",
                "\n",
                "print(\"Begin training\")\n",
                "\n",
                "cost_history, trained_Theta = NesterovGradientDescent(cost_func_ptr, 0.9, 0.3, init_Theta, 160)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Initializing neural network\n",
                        "Begin training\n",
                        " Iteration: 45 ; Cost value: 1.958934 ; Changing rate: [0.02811133] ; Gradient: [-2.53400427e-05]"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Extract back theta1, theta2\n",
                "breakpnt = (input_layer_size + 1) * hidden_layer_size\n",
                "Theta1 = trained_Theta[None:breakpnt, :].reshape((hidden_layer_size, input_layer_size + 1))\n",
                "Theta2 = trained_Theta[breakpnt:None, :].reshape((output_layer_size, hidden_layer_size + 1))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Calculate accuracy"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "correct_counter = 0\n",
                "for i in range(X.shape[0]): \n",
                "    x = X[i, :].reshape(-1, 1)\n",
                "    _, _, h, _, _ = hypothesis(x, Theta1, Theta2)\n",
                "    label = np.argmax(h)\n",
                "    if (label == y[i]):\n",
                "        correct_counter += 1\n",
                "\n",
                "print(\"Accuracy:\", correct_counter/X.shape[0])\n",
                "    "
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "Accuracy: 0.921\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "while True:\n",
                "    try:\n",
                "        # Choose a random number\n",
                "        randIdx = np.random.randint(0, X.shape[0] - 1)\n",
                "        x = X[randIdx]\n",
                "        # Predict\n",
                "        _, _, h, _, _ = hypothesis(x, Theta1, Theta2)\n",
                "        # Show result\n",
                "        label = np.argmax(h)\n",
                "        img = x.reshape((20, 20)).T\n",
                "        plt.imshow(img)\n",
                "        plt.title(f\"Label: {label}\", fontdict={\"fontsize\": 30})\n",
                "        plt.show()\n",
                "        time.sleep(1)\n",
                "        clear_output(wait=True)\n",
                "    except KeyboardInterrupt:\n",
                "        print(\"Stopped\")\n",
                "        break\n"
            ],
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": [
                            "<Figure size 432x288 with 1 Axes>"
                        ],
                        "image/png": "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"
                    },
                    "metadata": {
                        "needs_background": "light"
                    }
                }
            ],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit"
        },
        "interpreter": {
            "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}